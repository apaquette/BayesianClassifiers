{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "772987a3",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"0.1\"></a>\n",
    "# **Table of Contents**\n",
    "1. [Introduction](#1)\n",
    "2. [Business Understanding](#2)\n",
    "3. [Data Understanding](#3)\n",
    "4. [Data Preperation](#4)\n",
    "5. [Modeling](#5)\n",
    "6. [Evaluation](#6)\n",
    "7. [Improvements](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1936fbce",
   "metadata": {},
   "source": [
    "# **1. Introduction** <a class=\"anchor\" id=\"1\"></a>\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "This notebook will explore Feedforward Neural Networks by going through the CRISP-DM process. The goal is to gain insight into how to use FNN in Python.\n",
    "\n",
    "### Feedforward Neural Networks\n",
    "\n",
    "Feedforward Neural Networks (FNNs) are a type of neural network where the connection between nodes do not form any cycle. Information moves forward, from the input nodes, through the hidden nodes, to the output nodes. The following is the typical process of a FNN:\n",
    "\n",
    "**1. Forward Pass**\n",
    "\n",
    "Input data is fed into the input layer. Each neuron passes its signal forward to all neurons in the hidden layer. Each connection between neurons has an associated weight that determines the strength of the connection.\n",
    "\n",
    "**2. Activation Function**\n",
    "\n",
    "At each neuron in the hidden layer, the weighed sum of inputs is calculated, and then an activation function is applied. Common activation functions include sigmoid, tanh, and ReLU (Rectified Linear Unit).\n",
    "\n",
    "**3. Propagation**\n",
    "\n",
    "The output of each neuron becomes the input of the neurons in the next layer. This process continues until the output layer is reached.\n",
    "\n",
    "**4. Output**\n",
    "\n",
    "The output layer represents the predictions or classifications made by the neural network based on the input data.\n",
    "\n",
    "**5. Error Calculation and Backpropagation**\n",
    "\n",
    "The network's output is compared to the actual actual target value, and the error is calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea85272",
   "metadata": {},
   "source": [
    "# **2. Business Understanding** <a class=\"anchor\" id=\"2\"></a>\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "The dataset I will be using for this notebook is the [Phishing Url](https://www.kaggle.com/datasets/hemanthpingali/phishing-url?resource=download). I will be attempting to train a neural network to identify phishing urls.\n",
    "\n",
    "The dataset contains various features extracted from the urls including length, presence of elements (IP, TLDs), content-related attributes, technical indicators, and others. Altogether there are 87 such attributes in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88947a9",
   "metadata": {},
   "source": [
    "# **3. Data Understanding** <a class=\"anchor\" id=\"3\"></a>\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "We will now explore our dataset to understand the data we are working with. Our data is stored in a .parquet file, so we'll want to convert it to a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e665843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\alexa\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "C:\\Users\\alexa\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# This library will help us access our file\n",
    "try:\n",
    "    import os\n",
    "except:\n",
    "    !pip install os\n",
    "    import os\n",
    "    \n",
    "# This library is for data processing, and file I/O\n",
    "try:\n",
    "    import pandas as pd\n",
    "except:\n",
    "    !pip install pandas\n",
    "    import pandas as pd\n",
    "    \n",
    "try:\n",
    "    import numpy as np\n",
    "except:\n",
    "    !pip install numpy\n",
    "    import numpy as np\n",
    "\n",
    "# model training libraries\n",
    "try:\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "except:\n",
    "    !pip install sklearn\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "except:\n",
    "    !pip install sklearn\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "try:\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense\n",
    "except:\n",
    "    !pip install tensorflow\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense    \n",
    "    \n",
    "# Eval libraries\n",
    "try:\n",
    "    from sklearn.metrics import accuracy_score\n",
    "except:\n",
    "    !pip install sklearn\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "try:\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "except:\n",
    "    !pip install sklearn\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "try:\n",
    "    from sklearn.metrics import classification_report\n",
    "except:\n",
    "    !pip install sklearn\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "# visualize confusion matrix with seaborn heatmap\n",
    "try:\n",
    "    import seaborn as sns # for statistical data visualization\n",
    "except:\n",
    "    !pip install seaborn\n",
    "    import seaborn as sns # for statistical data visualization\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except:\n",
    "    !pip install matplotlib\n",
    "    import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99dea5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_working_directory = os.getcwd()\n",
    "file = r'\\input\\phishingURL.parquet' #this directory may differ for you\n",
    "data = current_working_directory + file\n",
    "\n",
    "# convert to a csv\n",
    "df = pd.read_parquet(data)\n",
    "df.to_csv(current_working_directory + r'\\input\\phishingURL.csv') \n",
    "\n",
    "# read the new csv\n",
    "data = current_working_directory + r'\\input\\phishingURL.csv'\n",
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fc5dd2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3772, 90)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c838ad3b",
   "metadata": {},
   "source": [
    "We can see that there are 3772 instances, and 90 attributes, which is more than what we were expecting from business understanding. Let's look at the columns and determine what we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a8ae496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>url</th>\n",
       "      <th>length_url</th>\n",
       "      <th>length_hostname</th>\n",
       "      <th>ip</th>\n",
       "      <th>nb_dots</th>\n",
       "      <th>nb_hyphens</th>\n",
       "      <th>nb_at</th>\n",
       "      <th>nb_qm</th>\n",
       "      <th>nb_and</th>\n",
       "      <th>...</th>\n",
       "      <th>domain_in_title</th>\n",
       "      <th>domain_with_copyright</th>\n",
       "      <th>whois_registered_domain</th>\n",
       "      <th>domain_registration_length</th>\n",
       "      <th>domain_age</th>\n",
       "      <th>web_traffic</th>\n",
       "      <th>dns_record</th>\n",
       "      <th>google_index</th>\n",
       "      <th>page_rank</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://clubedemilhagem.com/home.php</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>344</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>http://www.medicalnewstoday.com/articles/18893...</td>\n",
       "      <td>51</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>6106</td>\n",
       "      <td>737</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://en.wikipedia.org/wiki/NBC_Nightly_News</td>\n",
       "      <td>46</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>901</td>\n",
       "      <td>7134</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>http://secure.web894.com/customer_center/custo...</td>\n",
       "      <td>185</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>247</td>\n",
       "      <td>1944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Transaction_proc...</td>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>901</td>\n",
       "      <td>7134</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                url  length_url  \\\n",
       "0           0               https://clubedemilhagem.com/home.php          36   \n",
       "1           1  http://www.medicalnewstoday.com/articles/18893...          51   \n",
       "2           2     https://en.wikipedia.org/wiki/NBC_Nightly_News          46   \n",
       "3           3  http://secure.web894.com/customer_center/custo...         185   \n",
       "4           4  https://en.wikipedia.org/wiki/Transaction_proc...          52   \n",
       "\n",
       "   length_hostname  ip  nb_dots  nb_hyphens  nb_at  nb_qm  nb_and  ...  \\\n",
       "0               19   0        2           0      0      0       0  ...   \n",
       "1               24   0        3           0      0      0       0  ...   \n",
       "2               16   0        2           0      0      0       0  ...   \n",
       "3               17   1        2           1      0      1       2  ...   \n",
       "4               16   0        2           0      0      0       0  ...   \n",
       "\n",
       "   domain_in_title  domain_with_copyright  whois_registered_domain  \\\n",
       "0                1                      0                        0   \n",
       "1                1                      1                        0   \n",
       "2                0                      1                        0   \n",
       "3                1                      1                        0   \n",
       "4                0                      1                        0   \n",
       "\n",
       "   domain_registration_length  domain_age  web_traffic  dns_record  \\\n",
       "0                         344          21            0           0   \n",
       "1                         103        6106          737           0   \n",
       "2                         901        7134           12           0   \n",
       "3                         247        1944            0           0   \n",
       "4                         901        7134           12           0   \n",
       "\n",
       "   google_index  page_rank      status  \n",
       "0             1          0    phishing  \n",
       "1             1          6  legitimate  \n",
       "2             0          7  legitimate  \n",
       "3             1          0    phishing  \n",
       "4             0          7  legitimate  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b57b33",
   "metadata": {},
   "source": [
    "Here we can see that from our 90 columns, two are indices (first and second), and the third is the url, meaning that the remaining 87 columns match our expected attributes. We can drop the extra indice column during our data preperation phase, since they won't be necessary to train our model. We can also drop the url column, as the rest of the attributes are data about the url, which is what we want to use to make our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7b8004d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3772 entries, 0 to 3771\n",
      "Data columns (total 90 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Unnamed: 0                  3772 non-null   int64  \n",
      " 1   url                         3772 non-null   object \n",
      " 2   length_url                  3772 non-null   int64  \n",
      " 3   length_hostname             3772 non-null   int64  \n",
      " 4   ip                          3772 non-null   int64  \n",
      " 5   nb_dots                     3772 non-null   int64  \n",
      " 6   nb_hyphens                  3772 non-null   int64  \n",
      " 7   nb_at                       3772 non-null   int64  \n",
      " 8   nb_qm                       3772 non-null   int64  \n",
      " 9   nb_and                      3772 non-null   int64  \n",
      " 10  nb_or                       3772 non-null   int64  \n",
      " 11  nb_eq                       3772 non-null   int64  \n",
      " 12  nb_underscore               3772 non-null   int64  \n",
      " 13  nb_tilde                    3772 non-null   int64  \n",
      " 14  nb_percent                  3772 non-null   int64  \n",
      " 15  nb_slash                    3772 non-null   int64  \n",
      " 16  nb_star                     3772 non-null   int64  \n",
      " 17  nb_colon                    3772 non-null   int64  \n",
      " 18  nb_comma                    3772 non-null   int64  \n",
      " 19  nb_semicolumn               3772 non-null   int64  \n",
      " 20  nb_dollar                   3772 non-null   int64  \n",
      " 21  nb_space                    3772 non-null   int64  \n",
      " 22  nb_www                      3772 non-null   int64  \n",
      " 23  nb_com                      3772 non-null   int64  \n",
      " 24  nb_dslash                   3772 non-null   int64  \n",
      " 25  http_in_path                3772 non-null   int64  \n",
      " 26  https_token                 3772 non-null   int64  \n",
      " 27  ratio_digits_url            3772 non-null   float64\n",
      " 28  ratio_digits_host           3772 non-null   float64\n",
      " 29  punycode                    3772 non-null   int64  \n",
      " 30  port                        3772 non-null   int64  \n",
      " 31  tld_in_path                 3772 non-null   int64  \n",
      " 32  tld_in_subdomain            3772 non-null   int64  \n",
      " 33  abnormal_subdomain          3772 non-null   int64  \n",
      " 34  nb_subdomains               3772 non-null   int64  \n",
      " 35  prefix_suffix               3772 non-null   int64  \n",
      " 36  random_domain               3772 non-null   int64  \n",
      " 37  shortening_service          3772 non-null   int64  \n",
      " 38  path_extension              3772 non-null   int64  \n",
      " 39  nb_redirection              3772 non-null   int64  \n",
      " 40  nb_external_redirection     3772 non-null   int64  \n",
      " 41  length_words_raw            3772 non-null   int64  \n",
      " 42  char_repeat                 3772 non-null   int64  \n",
      " 43  shortest_words_raw          3772 non-null   int64  \n",
      " 44  shortest_word_host          3772 non-null   int64  \n",
      " 45  shortest_word_path          3772 non-null   int64  \n",
      " 46  longest_words_raw           3772 non-null   int64  \n",
      " 47  longest_word_host           3772 non-null   int64  \n",
      " 48  longest_word_path           3772 non-null   int64  \n",
      " 49  avg_words_raw               3772 non-null   float64\n",
      " 50  avg_word_host               3772 non-null   float64\n",
      " 51  avg_word_path               3772 non-null   float64\n",
      " 52  phish_hints                 3772 non-null   int64  \n",
      " 53  domain_in_brand             3772 non-null   int64  \n",
      " 54  brand_in_subdomain          3772 non-null   int64  \n",
      " 55  brand_in_path               3772 non-null   int64  \n",
      " 56  suspecious_tld              3772 non-null   int64  \n",
      " 57  statistical_report          3772 non-null   int64  \n",
      " 58  nb_hyperlinks               3772 non-null   int64  \n",
      " 59  ratio_intHyperlinks         3772 non-null   float64\n",
      " 60  ratio_extHyperlinks         3772 non-null   float64\n",
      " 61  ratio_nullHyperlinks        3772 non-null   int64  \n",
      " 62  nb_extCSS                   3772 non-null   int64  \n",
      " 63  ratio_intRedirection        3772 non-null   int64  \n",
      " 64  ratio_extRedirection        3772 non-null   float64\n",
      " 65  ratio_intErrors             3772 non-null   int64  \n",
      " 66  ratio_extErrors             3772 non-null   float64\n",
      " 67  login_form                  3772 non-null   int64  \n",
      " 68  external_favicon            3772 non-null   int64  \n",
      " 69  links_in_tags               3772 non-null   float64\n",
      " 70  submit_email                3772 non-null   int64  \n",
      " 71  ratio_intMedia              3772 non-null   float64\n",
      " 72  ratio_extMedia              3772 non-null   float64\n",
      " 73  sfh                         3772 non-null   int64  \n",
      " 74  iframe                      3772 non-null   int64  \n",
      " 75  popup_window                3772 non-null   int64  \n",
      " 76  safe_anchor                 3772 non-null   float64\n",
      " 77  onmouseover                 3772 non-null   int64  \n",
      " 78  right_clic                  3772 non-null   int64  \n",
      " 79  empty_title                 3772 non-null   int64  \n",
      " 80  domain_in_title             3772 non-null   int64  \n",
      " 81  domain_with_copyright       3772 non-null   int64  \n",
      " 82  whois_registered_domain     3772 non-null   int64  \n",
      " 83  domain_registration_length  3772 non-null   int64  \n",
      " 84  domain_age                  3772 non-null   int64  \n",
      " 85  web_traffic                 3772 non-null   int64  \n",
      " 86  dns_record                  3772 non-null   int64  \n",
      " 87  google_index                3772 non-null   int64  \n",
      " 88  page_rank                   3772 non-null   int64  \n",
      " 89  status                      3772 non-null   object \n",
      "dtypes: float64(13), int64(75), object(2)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0db07e",
   "metadata": {},
   "source": [
    "Here we can see that we have no missing values for our 3772 records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc6af70",
   "metadata": {},
   "source": [
    "### Explore Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b19bfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 categorical variables\n",
      "\n",
      "The categorical variables are: ['url', 'status']\n"
     ]
    }
   ],
   "source": [
    "# identify categorical variables\n",
    "\n",
    "categorical = [var for var in df.columns if df[var].dtype=='O']\n",
    "\n",
    "print(f'There are {len(categorical)} categorical variables\\n')\n",
    "print(f'The categorical variables are: {categorical}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0002a03b",
   "metadata": {},
   "source": [
    "### Explore Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7275f6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 88 numerical variables\n",
      "\n",
      "The numerical variables are: ['Unnamed: 0', 'length_url', 'length_hostname', 'ip', 'nb_dots', 'nb_hyphens', 'nb_at', 'nb_qm', 'nb_and', 'nb_or', 'nb_eq', 'nb_underscore', 'nb_tilde', 'nb_percent', 'nb_slash', 'nb_star', 'nb_colon', 'nb_comma', 'nb_semicolumn', 'nb_dollar', 'nb_space', 'nb_www', 'nb_com', 'nb_dslash', 'http_in_path', 'https_token', 'ratio_digits_url', 'ratio_digits_host', 'punycode', 'port', 'tld_in_path', 'tld_in_subdomain', 'abnormal_subdomain', 'nb_subdomains', 'prefix_suffix', 'random_domain', 'shortening_service', 'path_extension', 'nb_redirection', 'nb_external_redirection', 'length_words_raw', 'char_repeat', 'shortest_words_raw', 'shortest_word_host', 'shortest_word_path', 'longest_words_raw', 'longest_word_host', 'longest_word_path', 'avg_words_raw', 'avg_word_host', 'avg_word_path', 'phish_hints', 'domain_in_brand', 'brand_in_subdomain', 'brand_in_path', 'suspecious_tld', 'statistical_report', 'nb_hyperlinks', 'ratio_intHyperlinks', 'ratio_extHyperlinks', 'ratio_nullHyperlinks', 'nb_extCSS', 'ratio_intRedirection', 'ratio_extRedirection', 'ratio_intErrors', 'ratio_extErrors', 'login_form', 'external_favicon', 'links_in_tags', 'submit_email', 'ratio_intMedia', 'ratio_extMedia', 'sfh', 'iframe', 'popup_window', 'safe_anchor', 'onmouseover', 'right_clic', 'empty_title', 'domain_in_title', 'domain_with_copyright', 'whois_registered_domain', 'domain_registration_length', 'domain_age', 'web_traffic', 'dns_record', 'google_index', 'page_rank']\n"
     ]
    }
   ],
   "source": [
    "# identify numerical variables\n",
    "\n",
    "numerical = [var for var in df.columns if df[var].dtype!='O']\n",
    "\n",
    "print(f'There are {len(numerical)} numerical variables\\n')\n",
    "print(f'The numerical variables are: {numerical}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c18d12",
   "metadata": {},
   "source": [
    "# **4. Data Preperation** <a class=\"anchor\" id=\"4\"></a>\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "During the Data Understanding phase, we noticed there were some unecessary columns in our dataset. We will drop the first two columns, as they won't helpful for us to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0484c24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length_url</th>\n",
       "      <th>length_hostname</th>\n",
       "      <th>ip</th>\n",
       "      <th>nb_dots</th>\n",
       "      <th>nb_hyphens</th>\n",
       "      <th>nb_at</th>\n",
       "      <th>nb_qm</th>\n",
       "      <th>nb_and</th>\n",
       "      <th>nb_or</th>\n",
       "      <th>nb_eq</th>\n",
       "      <th>...</th>\n",
       "      <th>domain_in_title</th>\n",
       "      <th>domain_with_copyright</th>\n",
       "      <th>whois_registered_domain</th>\n",
       "      <th>domain_registration_length</th>\n",
       "      <th>domain_age</th>\n",
       "      <th>web_traffic</th>\n",
       "      <th>dns_record</th>\n",
       "      <th>google_index</th>\n",
       "      <th>page_rank</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>344</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>6106</td>\n",
       "      <td>737</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>901</td>\n",
       "      <td>7134</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>185</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>247</td>\n",
       "      <td>1944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>901</td>\n",
       "      <td>7134</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   length_url  length_hostname  ip  nb_dots  nb_hyphens  nb_at  nb_qm  nb_and  \\\n",
       "0          36               19   0        2           0      0      0       0   \n",
       "1          51               24   0        3           0      0      0       0   \n",
       "2          46               16   0        2           0      0      0       0   \n",
       "3         185               17   1        2           1      0      1       2   \n",
       "4          52               16   0        2           0      0      0       0   \n",
       "\n",
       "   nb_or  nb_eq  ...  domain_in_title  domain_with_copyright  \\\n",
       "0      0      0  ...                1                      0   \n",
       "1      0      0  ...                1                      1   \n",
       "2      0      0  ...                0                      1   \n",
       "3      0      3  ...                1                      1   \n",
       "4      0      0  ...                0                      1   \n",
       "\n",
       "   whois_registered_domain  domain_registration_length  domain_age  \\\n",
       "0                        0                         344          21   \n",
       "1                        0                         103        6106   \n",
       "2                        0                         901        7134   \n",
       "3                        0                         247        1944   \n",
       "4                        0                         901        7134   \n",
       "\n",
       "   web_traffic  dns_record  google_index  page_rank      status  \n",
       "0            0           0             1          0    phishing  \n",
       "1          737           0             1          6  legitimate  \n",
       "2           12           0             0          7  legitimate  \n",
       "3            0           0             1          0    phishing  \n",
       "4           12           0             0          7  legitimate  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(df.columns[:2], inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a065392",
   "metadata": {},
   "source": [
    "Now we want to extract our target variable from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ca1e8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'status'\n",
    "\n",
    "X_target = df.drop([target_variable], axis=1)\n",
    "\n",
    "y = df[target_variable]\n",
    "df.drop([target_variable], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626f3a01",
   "metadata": {},
   "source": [
    "Next we want to scale our values to ensure all attributes contribute equally to the model's training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "977bd01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length_url</th>\n",
       "      <th>length_hostname</th>\n",
       "      <th>ip</th>\n",
       "      <th>nb_dots</th>\n",
       "      <th>nb_hyphens</th>\n",
       "      <th>nb_at</th>\n",
       "      <th>nb_qm</th>\n",
       "      <th>nb_and</th>\n",
       "      <th>nb_or</th>\n",
       "      <th>nb_eq</th>\n",
       "      <th>...</th>\n",
       "      <th>empty_title</th>\n",
       "      <th>domain_in_title</th>\n",
       "      <th>domain_with_copyright</th>\n",
       "      <th>whois_registered_domain</th>\n",
       "      <th>domain_registration_length</th>\n",
       "      <th>domain_age</th>\n",
       "      <th>web_traffic</th>\n",
       "      <th>dns_record</th>\n",
       "      <th>google_index</th>\n",
       "      <th>page_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>344</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>6106</td>\n",
       "      <td>737</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>901</td>\n",
       "      <td>7134</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>185</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>247</td>\n",
       "      <td>1944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>901</td>\n",
       "      <td>7134</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3767</th>\n",
       "      <td>34</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373</td>\n",
       "      <td>6202</td>\n",
       "      <td>7701846</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3768</th>\n",
       "      <td>54</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>6071</td>\n",
       "      <td>14420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3769</th>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>238</td>\n",
       "      <td>5971</td>\n",
       "      <td>402341</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>550</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>349</td>\n",
       "      <td>6591</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>77</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>5767</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3772 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      length_url  length_hostname  ip  nb_dots  nb_hyphens  nb_at  nb_qm  \\\n",
       "0             36               19   0        2           0      0      0   \n",
       "1             51               24   0        3           0      0      0   \n",
       "2             46               16   0        2           0      0      0   \n",
       "3            185               17   1        2           1      0      1   \n",
       "4             52               16   0        2           0      0      0   \n",
       "...          ...              ...  ..      ...         ...    ...    ...   \n",
       "3767          34               26   0        2           0      0      0   \n",
       "3768          54               14   0        2           0      0      0   \n",
       "3769          25               16   0        2           0      0      0   \n",
       "3770         550               25   1        5          24      0      1   \n",
       "3771          77               23   1        1           0      0      0   \n",
       "\n",
       "      nb_and  nb_or  nb_eq  ...  empty_title  domain_in_title  \\\n",
       "0          0      0      0  ...            0                1   \n",
       "1          0      0      0  ...            0                1   \n",
       "2          0      0      0  ...            0                0   \n",
       "3          2      0      3  ...            0                1   \n",
       "4          0      0      0  ...            0                0   \n",
       "...      ...    ...    ...  ...          ...              ...   \n",
       "3767       0      0      0  ...            0                0   \n",
       "3768       0      0      0  ...            0                1   \n",
       "3769       0      0      0  ...            0                0   \n",
       "3770       9      0     10  ...            0                1   \n",
       "3771       0      0      0  ...            0                1   \n",
       "\n",
       "      domain_with_copyright  whois_registered_domain  \\\n",
       "0                         0                        0   \n",
       "1                         1                        0   \n",
       "2                         1                        0   \n",
       "3                         1                        0   \n",
       "4                         1                        0   \n",
       "...                     ...                      ...   \n",
       "3767                      0                        0   \n",
       "3768                      1                        0   \n",
       "3769                      0                        0   \n",
       "3770                      1                        0   \n",
       "3771                      0                        0   \n",
       "\n",
       "      domain_registration_length  domain_age  web_traffic  dns_record  \\\n",
       "0                            344          21            0           0   \n",
       "1                            103        6106          737           0   \n",
       "2                            901        7134           12           0   \n",
       "3                            247        1944            0           0   \n",
       "4                            901        7134           12           0   \n",
       "...                          ...         ...          ...         ...   \n",
       "3767                         373        6202      7701846           0   \n",
       "3768                         139        6071        14420           0   \n",
       "3769                         238        5971       402341           0   \n",
       "3770                         349        6591           30           0   \n",
       "3771                          77        5767            0           0   \n",
       "\n",
       "      google_index  page_rank  \n",
       "0                1          0  \n",
       "1                1          6  \n",
       "2                0          7  \n",
       "3                1          0  \n",
       "4                0          7  \n",
       "...            ...        ...  \n",
       "3767             0          5  \n",
       "3768             0          5  \n",
       "3769             0          3  \n",
       "3770             1          4  \n",
       "3771             1          2  \n",
       "\n",
       "[3772 rows x 87 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f459933",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length_url</th>\n",
       "      <th>length_hostname</th>\n",
       "      <th>ip</th>\n",
       "      <th>nb_dots</th>\n",
       "      <th>nb_hyphens</th>\n",
       "      <th>nb_at</th>\n",
       "      <th>nb_qm</th>\n",
       "      <th>nb_and</th>\n",
       "      <th>nb_or</th>\n",
       "      <th>nb_eq</th>\n",
       "      <th>...</th>\n",
       "      <th>empty_title</th>\n",
       "      <th>domain_in_title</th>\n",
       "      <th>domain_with_copyright</th>\n",
       "      <th>whois_registered_domain</th>\n",
       "      <th>domain_registration_length</th>\n",
       "      <th>domain_age</th>\n",
       "      <th>web_traffic</th>\n",
       "      <th>dns_record</th>\n",
       "      <th>google_index</th>\n",
       "      <th>page_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.530043</td>\n",
       "      <td>-0.192143</td>\n",
       "      <td>-0.428870</td>\n",
       "      <td>-0.374353</td>\n",
       "      <td>-0.458789</td>\n",
       "      <td>-0.151506</td>\n",
       "      <td>-0.384054</td>\n",
       "      <td>-0.211981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.307427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.37083</td>\n",
       "      <td>0.545898</td>\n",
       "      <td>-0.890858</td>\n",
       "      <td>-0.27377</td>\n",
       "      <td>-0.200046</td>\n",
       "      <td>-1.303867</td>\n",
       "      <td>-0.427241</td>\n",
       "      <td>-0.135494</td>\n",
       "      <td>0.917005</td>\n",
       "      <td>-1.255602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.216023</td>\n",
       "      <td>0.229918</td>\n",
       "      <td>-0.428870</td>\n",
       "      <td>0.365720</td>\n",
       "      <td>-0.458789</td>\n",
       "      <td>-0.151506</td>\n",
       "      <td>-0.384054</td>\n",
       "      <td>-0.211981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.307427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.37083</td>\n",
       "      <td>0.545898</td>\n",
       "      <td>1.122513</td>\n",
       "      <td>-0.27377</td>\n",
       "      <td>-0.538596</td>\n",
       "      <td>0.650155</td>\n",
       "      <td>-0.426863</td>\n",
       "      <td>-0.135494</td>\n",
       "      <td>0.917005</td>\n",
       "      <td>1.119788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.320696</td>\n",
       "      <td>-0.445380</td>\n",
       "      <td>-0.428870</td>\n",
       "      <td>-0.374353</td>\n",
       "      <td>-0.458789</td>\n",
       "      <td>-0.151506</td>\n",
       "      <td>-0.384054</td>\n",
       "      <td>-0.211981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.307427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.37083</td>\n",
       "      <td>-1.831846</td>\n",
       "      <td>1.122513</td>\n",
       "      <td>-0.27377</td>\n",
       "      <td>0.582413</td>\n",
       "      <td>0.980268</td>\n",
       "      <td>-0.427235</td>\n",
       "      <td>-0.135494</td>\n",
       "      <td>-1.090507</td>\n",
       "      <td>1.515686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.589220</td>\n",
       "      <td>-0.360967</td>\n",
       "      <td>2.331708</td>\n",
       "      <td>-0.374353</td>\n",
       "      <td>0.006538</td>\n",
       "      <td>-0.151506</td>\n",
       "      <td>2.391141</td>\n",
       "      <td>2.310396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.843696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.37083</td>\n",
       "      <td>0.545898</td>\n",
       "      <td>1.122513</td>\n",
       "      <td>-0.27377</td>\n",
       "      <td>-0.336309</td>\n",
       "      <td>-0.686351</td>\n",
       "      <td>-0.427241</td>\n",
       "      <td>-0.135494</td>\n",
       "      <td>0.917005</td>\n",
       "      <td>-1.255602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.195088</td>\n",
       "      <td>-0.445380</td>\n",
       "      <td>-0.428870</td>\n",
       "      <td>-0.374353</td>\n",
       "      <td>-0.458789</td>\n",
       "      <td>-0.151506</td>\n",
       "      <td>-0.384054</td>\n",
       "      <td>-0.211981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.307427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.37083</td>\n",
       "      <td>-1.831846</td>\n",
       "      <td>1.122513</td>\n",
       "      <td>-0.27377</td>\n",
       "      <td>0.582413</td>\n",
       "      <td>0.980268</td>\n",
       "      <td>-0.427235</td>\n",
       "      <td>-0.135494</td>\n",
       "      <td>-1.090507</td>\n",
       "      <td>1.515686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   length_url  length_hostname        ip   nb_dots  nb_hyphens     nb_at  \\\n",
       "0   -0.530043        -0.192143 -0.428870 -0.374353   -0.458789 -0.151506   \n",
       "1   -0.216023         0.229918 -0.428870  0.365720   -0.458789 -0.151506   \n",
       "2   -0.320696        -0.445380 -0.428870 -0.374353   -0.458789 -0.151506   \n",
       "3    2.589220        -0.360967  2.331708 -0.374353    0.006538 -0.151506   \n",
       "4   -0.195088        -0.445380 -0.428870 -0.374353   -0.458789 -0.151506   \n",
       "\n",
       "      nb_qm    nb_and  nb_or     nb_eq  ...  empty_title  domain_in_title  \\\n",
       "0 -0.384054 -0.211981    0.0 -0.307427  ...     -0.37083         0.545898   \n",
       "1 -0.384054 -0.211981    0.0 -0.307427  ...     -0.37083         0.545898   \n",
       "2 -0.384054 -0.211981    0.0 -0.307427  ...     -0.37083        -1.831846   \n",
       "3  2.391141  2.310396    0.0  2.843696  ...     -0.37083         0.545898   \n",
       "4 -0.384054 -0.211981    0.0 -0.307427  ...     -0.37083        -1.831846   \n",
       "\n",
       "   domain_with_copyright  whois_registered_domain  domain_registration_length  \\\n",
       "0              -0.890858                 -0.27377                   -0.200046   \n",
       "1               1.122513                 -0.27377                   -0.538596   \n",
       "2               1.122513                 -0.27377                    0.582413   \n",
       "3               1.122513                 -0.27377                   -0.336309   \n",
       "4               1.122513                 -0.27377                    0.582413   \n",
       "\n",
       "   domain_age  web_traffic  dns_record  google_index  page_rank  \n",
       "0   -1.303867    -0.427241   -0.135494      0.917005  -1.255602  \n",
       "1    0.650155    -0.426863   -0.135494      0.917005   1.119788  \n",
       "2    0.980268    -0.427235   -0.135494     -1.090507   1.515686  \n",
       "3   -0.686351    -0.427241   -0.135494      0.917005  -1.255602  \n",
       "4    0.980268    -0.427235   -0.135494     -1.090507   1.515686  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(df)\n",
    "df_scaled = pd.DataFrame(data=X, columns=df.columns)\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97846698",
   "metadata": {},
   "source": [
    "Now that our data is scaled, we want to split our dataset into a training and testing set. Our testing set will allow us to test our model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d408b82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (2640, 87) (2640,)\n",
      "Test set: (1132, 87) (1132,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=4)\n",
    "\n",
    "# encode the training sets\n",
    "y_train = (y_train == 'legitimate').astype(int)\n",
    "y_test = (y_test == 'legitimate').astype(int)\n",
    "\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cff3a80",
   "metadata": {},
   "source": [
    "# **5. Modeling** <a class=\"anchor\" id=\"5\"></a>\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "Our data is ready to train our model. In this notebook, we will be using tenserflow to train our model. Neural Network models consists of an input layer, hidden layer, and output layer. We will define each layer, and add them to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8e37282",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "fnn_model = Sequential()\n",
    "\n",
    "# input layer neruons count equal to number of features and ReLU activation\n",
    "input_layer = Dense(X_train.shape[1], input_dim=X_train.shape[1], activation='relu')\n",
    "\n",
    "# hidden layer with 64 neurons for the first, and 32 for the second, and ReLU activation\n",
    "hidden_layer_one = Dense(64, activation = 'relu')\n",
    "hidden_layer_two = Dense(32, activation = 'relu')\n",
    "\n",
    "# output layer with 1 neuron and sigmoid activation (binary classification)\n",
    "output_layer = Dense(1, activation='sigmoid')\n",
    "\n",
    "# add the layers to the model\n",
    "fnn_model.add(input_layer)\n",
    "fnn_model.add(hidden_layer_one)\n",
    "fnn_model.add(hidden_layer_two)\n",
    "fnn_model.add(output_layer)\n",
    "\n",
    "# compile the model\n",
    "fnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64bdab79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8521 - loss: 0.4343 - val_accuracy: 0.9284 - val_loss: 0.1779\n",
      "Epoch 2/10\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.9432 - loss: 0.1573 - val_accuracy: 0.9382 - val_loss: 0.1549\n",
      "Epoch 3/10\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.9670 - loss: 0.1064 - val_accuracy: 0.9382 - val_loss: 0.1648\n",
      "Epoch 4/10\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.9646 - loss: 0.1044 - val_accuracy: 0.9435 - val_loss: 0.1453\n",
      "Epoch 5/10\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.9669 - loss: 0.0852 - val_accuracy: 0.9452 - val_loss: 0.1447\n",
      "Epoch 6/10\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.9771 - loss: 0.0702 - val_accuracy: 0.9435 - val_loss: 0.1532\n",
      "Epoch 7/10\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.9778 - loss: 0.0645 - val_accuracy: 0.9337 - val_loss: 0.2008\n",
      "Epoch 8/10\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9853 - loss: 0.0514 - val_accuracy: 0.9443 - val_loss: 0.1570\n",
      "Epoch 9/10\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9897 - loss: 0.0373 - val_accuracy: 0.9373 - val_loss: 0.1777\n",
      "Epoch 10/10\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9933 - loss: 0.0258 - val_accuracy: 0.9496 - val_loss: 0.1694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2cd646eaac0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "fnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "422095ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    }
   ],
   "source": [
    "y_pred = fnn_model.predict(X_test)\n",
    "y_pred = (y_pred >= 0.5).astype(int) # round probabilities to get binary labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c429135",
   "metadata": {},
   "source": [
    "# **6. Evaluation** <a class=\"anchor\" id=\"6\"></a>\n",
    "[Table of Contents](#0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d8e2025",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step\n",
      "Model accuracy score: 0.9496\n",
      "Training-set accuracy score: 0.9932\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = fnn_model.predict(X_train)\n",
    "y_pred_train = (y_pred_train >= 0.5).astype(int) # round probabilities to get binary labels\n",
    "    \n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86163c6d",
   "metadata": {},
   "source": [
    "The trainin-set accuracy score is 0.9440 while the test-set accuracy is 0.9947. The two values differ by about 5%, which indicates there is little overfitting in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc66d1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy score: 0.5044\n"
     ]
    }
   ],
   "source": [
    "# return the most frequent value\n",
    "most_frequent = (y_test == 0).sum() if (y_test == 0).sum() >= (y_test == 1).sum() else (y_test == 1).sum()\n",
    "\n",
    "null_accuracy = most_frequent/len(y_test)\n",
    "print('Null accuracy score: {0:0.4f}'. format(null_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b9dba4",
   "metadata": {},
   "source": [
    "Our model accuracy score is 0.9470 while our null accuracy is 0.5044. Having a model accuracy score that is higher than the null accuracy is indicative that our model is doing a good job at predicting the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea116c6f",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "A confusion matrix is a tool for summarizing the performance of a classification algorithm. A confusion matrix will give us a clear picture of classification model performance and the types of errors produced by the model. It gives us a summary of correct and incorrect predictions broken down by each category. The summary is represented in a tabular form.\n",
    "\n",
    "\n",
    "Four types of outcomes are possible while evaluating a classification model performance. These four outcomes are described below:-\n",
    "\n",
    "\n",
    "**True Positives (TP)** – True Positives occur when we predict an observation belongs to a certain class and the observation actually belongs to that class.\n",
    "\n",
    "\n",
    "**True Negatives (TN)** – True Negatives occur when we predict an observation does not belong to a certain class and the observation actually does not belong to that class.\n",
    "\n",
    "\n",
    "**False Positives (FP)** – False Positives occur when we predict an observation belongs to a    certain class but the observation actually does not belong to that class. This type of error is called **Type I error.**\n",
    "\n",
    "\n",
    "\n",
    "**False Negatives (FN)** – False Negatives occur when we predict an observation does not belong to a certain class but the observation actually belongs to that class. This is a very serious error and it is called **Type II error.**\n",
    "\n",
    "\n",
    "\n",
    "These four outcomes are summarized in a confusion matrix given below.\n",
    "\n",
    "#### from Phrashant Banerjee [Naive Bayes Classifier in Python](https://www.kaggle.com/code/prashant111/naive-bayes-classifier-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be16afe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[536  25]\n",
      " [ 32 539]]\n",
      "\n",
      "True Positives(TP) =  536\n",
      "\n",
      "True Negatives(TN) =  539\n",
      "\n",
      "False Positives(FP) =  25\n",
      "\n",
      "False Negatives(FN) =  32\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "\n",
    "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
    "\n",
    "print('\\nFalse Negatives(FN) = ', cm[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d001da",
   "metadata": {},
   "source": [
    "The confusion matrix shows `545 + 527 = 1072 correct predictions` and `16 + 44 = 60 incorrect predictions`.\n",
    "\n",
    "\n",
    "In this case, we have\n",
    "\n",
    "\n",
    "- `True Positives` (Actual Positive:1 and Predict Positive:1) - 545\n",
    "\n",
    "\n",
    "- `True Negatives` (Actual Negative:0 and Predict Negative:0) - 527\n",
    "\n",
    "\n",
    "- `False Positives` (Actual Negative:0 but Predict Positive:1) - 16 `(Type I error)`\n",
    "\n",
    "\n",
    "- `False Negatives` (Actual Positive:1 but Predict Negative:0) - 44 `(Type II error)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5234e8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Phishing', 'Actual Legitimate'], \n",
    "                                 index=['Predict Phishing', 'Predict Legitimate'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e3a6ae",
   "metadata": {},
   "source": [
    "### Classification Report\n",
    "\n",
    "\n",
    "**Classification report** is another way to evaluate the classification model performance. It displays the  **precision**, **recall**, **f1** and **support** scores for the model.\n",
    "\n",
    "We can print a classification report as follows:-\n",
    "#### from Phrashant Banerjee [Naive Bayes Classifier in Python](https://www.kaggle.com/code/prashant111/naive-bayes-classifier-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05ae95db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       561\n",
      "           1       0.96      0.94      0.95       571\n",
      "\n",
      "    accuracy                           0.95      1132\n",
      "   macro avg       0.95      0.95      0.95      1132\n",
      "weighted avg       0.95      0.95      0.95      1132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97fe6f",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "**Accuracy** measures the overall correctness of the predictions. It is a general indicator of how well the model is performing.\n",
    "\n",
    "Mathematically, accuracy can be defined as the ratio of `(TP + FP) to (TP + FP + FN + TN)`\n",
    "\n",
    "### Precision\n",
    "\n",
    "\n",
    "**Precision** can be defined as the percentage of correctly predicted positive outcomes out of all the predicted positive outcomes. It can be given as the ratio of true positives (TP) to the sum of true and false positives (TP + FP). \n",
    "\n",
    "\n",
    "So, **Precision** identifies the proportion of correctly predicted positive outcome. It is more concerned with the positive class than the negative class.\n",
    "\n",
    "\n",
    "\n",
    "Mathematically, precision can be defined as the ratio of `TP to (TP + FP)`.\n",
    "#### from Phrashant Banerjee [Naive Bayes Classifier in Python](https://www.kaggle.com/code/prashant111/naive-bayes-classifier-in-python)\n",
    "\n",
    "### Recall\n",
    "\n",
    "\n",
    "Recall can be defined as the percentage of correctly predicted positive outcomes out of all the actual positive outcomes.\n",
    "It can be given as the ratio of true positives (TP) to the sum of true positives and false negatives (TP + FN). **Recall** is also called **Sensitivity**.\n",
    "\n",
    "\n",
    "**Recall** identifies the proportion of correctly predicted actual positives.\n",
    "\n",
    "\n",
    "Mathematically, recall can be given as the ratio of `TP to (TP + FN)`.\n",
    "#### from Phrashant Banerjee [Naive Bayes Classifier in Python](https://www.kaggle.com/code/prashant111/naive-bayes-classifier-in-python)\n",
    "\n",
    "### Specificity\n",
    "\n",
    "**Specificity** represents the propertion of correctly identified actual negatives. It helps us understand how well the model can idenitfy instances that don't belong the the positive class. High specificity is indicative that the model is good at avoiding false positives. Low specificity is indicative that the model is misclassifying negative instances as positive.\n",
    "\n",
    "Mathematically, specificity can be given as the ratio of `TN to (TN + FP)`\n",
    "\n",
    "### Negative Predictive Value (NPV)\n",
    "**NPV** asses the likelihood that a negative prediction is correct. High NPV indicates the model is correctly idenitfying true negatives. Low NPV indicates the model is missclassifying negative instances.\n",
    "\n",
    "Mathematically, NPV can be given as the ratio of `TN to (TN + FN)`\n",
    "\n",
    "### f1-score\n",
    "\n",
    "\n",
    "**f1-score** is the weighted harmonic mean of precision and recall. The best possible **f1-score** would be 1.0 and the worst \n",
    "would be 0.0.  **f1-score** is the harmonic mean of precision and recall. So, **f1-score** is always lower than accuracy measures as they embed precision and recall into their computation. The weighted average of `f1-score` should be used to \n",
    "compare classifier models, not global accuracy.\n",
    "\n",
    "Mathematically, f1-score can be given by the following formula: `2 x (Percision x Recall)/(Precision + Recall)`\n",
    "\n",
    "#### from Phrashant Banerjee [Naive Bayes Classifier in Python](https://www.kaggle.com/code/prashant111/naive-bayes-classifier-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12f402df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9496\n",
      "Precision : 0.9554\n",
      "Recall: 0.9437\n",
      "Specificity : 0.9557\n",
      "NPV: 0.9440\n",
      "F1 Score: 0.9495\n",
      "Balanced Accuracy: 0.9497\n"
     ]
    }
   ],
   "source": [
    "TP = cm[0,0]\n",
    "TN = cm[1,1]\n",
    "FP = cm[0,1]\n",
    "FN = cm[1,0]\n",
    "\n",
    "precision = TP / float(TP + FP)\n",
    "recall = TP / float(TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "negative_predictive_value = TN / (TN + FN)\n",
    "accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
    "f1_score = 2*((precision * recall) / (precision + recall))\n",
    "balanced_accuracy = (recall + specificity) / 2\n",
    "\n",
    "print('Accuracy : {0:0.4f}'.format(accuracy))\n",
    "print('Precision : {0:0.4f}'.format(precision))\n",
    "print('Recall: {0:0.4f}'.format(recall))\n",
    "print('Specificity : {0:0.4f}'.format(specificity))\n",
    "print('NPV: {0:0.4f}'.format(negative_predictive_value))\n",
    "print('F1 Score: {0:0.4f}'.format(f1_score))\n",
    "print('Balanced Accuracy: {0:0.4f}'.format(balanced_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dd1988",
   "metadata": {},
   "source": [
    "# **7. Improvements** <a class=\"anchor\" id=\"7\"></a>\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "Now that we've evaluated our model, we can reflect on our result and see if there are any improvements to be made.\n",
    "\n",
    "Given our results of `94.7%`, we can conclude that our model is exceedingly well trained to accurately predicts if urls are legitimate or phishing. From this point forward, our goal would be to try and train the model on fewer attributes to see if we can maintain accuracy with less data. 87 attributes is a lot of attributes to make predictions, and it would be more useful for our use-case to reduce the number of attributes, especially if we can maintain a high level of accuracy.\n",
    "\n",
    "If we want to implement this model in a useful way in the future, it is easier for us to work with attributes that are easily obtainable from the url. Such attributes include the following:\n",
    "\n",
    "- length_url\n",
    "- length_hostname\n",
    "- nb_dots\n",
    "- nb_hyphens\n",
    "- nb_at\n",
    "- nb_qm\n",
    "- nb_and\n",
    "- nb_or\n",
    "- nb_eq\n",
    "- nb_underscore\n",
    "- nb_tilde\n",
    "- nb_percent\n",
    "- nb_slash\n",
    "- nb_star\n",
    "- nb_colon\n",
    "- nb_comma\n",
    "- nb_semicolumn\n",
    "- nb_dollar\n",
    "- nb_space\n",
    "- nb_www\n",
    "- nb_com\n",
    "- nb_dslash\n",
    "- http_in_path\n",
    "- nb_subdomains\n",
    "\n",
    "These attributes can be directly derives from the url string, making them especially useful in a real-world application of our model if we can train it accurately on just these attributes. This would also bring our total attributes down from 87 to 24, meaning we need less data to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d08629d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_working_directory = os.getcwd()\n",
    "file = r'\\input\\phishingURL.parquet' #this directory may differ for you\n",
    "data = current_working_directory + file\n",
    "\n",
    "# convert to a csv\n",
    "df = pd.read_parquet(data)\n",
    "df.to_csv(current_working_directory + r'\\input\\phishingURL.csv') \n",
    "\n",
    "# read the new csv\n",
    "data = current_working_directory + r'\\input\\phishingURL.csv'\n",
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a803e47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length_url</th>\n",
       "      <th>length_hostname</th>\n",
       "      <th>nb_dots</th>\n",
       "      <th>nb_hyphens</th>\n",
       "      <th>nb_at</th>\n",
       "      <th>nb_qm</th>\n",
       "      <th>nb_and</th>\n",
       "      <th>nb_or</th>\n",
       "      <th>nb_eq</th>\n",
       "      <th>nb_underscore</th>\n",
       "      <th>...</th>\n",
       "      <th>nb_comma</th>\n",
       "      <th>nb_semicolumn</th>\n",
       "      <th>nb_dollar</th>\n",
       "      <th>nb_space</th>\n",
       "      <th>nb_www</th>\n",
       "      <th>nb_com</th>\n",
       "      <th>nb_dslash</th>\n",
       "      <th>http_in_path</th>\n",
       "      <th>nb_subdomains</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>185</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3767</th>\n",
       "      <td>34</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3768</th>\n",
       "      <td>54</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3769</th>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>550</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>77</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3772 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      length_url  length_hostname  nb_dots  nb_hyphens  nb_at  nb_qm  nb_and  \\\n",
       "0             36               19        2           0      0      0       0   \n",
       "1             51               24        3           0      0      0       0   \n",
       "2             46               16        2           0      0      0       0   \n",
       "3            185               17        2           1      0      1       2   \n",
       "4             52               16        2           0      0      0       0   \n",
       "...          ...              ...      ...         ...    ...    ...     ...   \n",
       "3767          34               26        2           0      0      0       0   \n",
       "3768          54               14        2           0      0      0       0   \n",
       "3769          25               16        2           0      0      0       0   \n",
       "3770         550               25        5          24      0      1       9   \n",
       "3771          77               23        1           0      0      0       0   \n",
       "\n",
       "      nb_or  nb_eq  nb_underscore  ...  nb_comma  nb_semicolumn  nb_dollar  \\\n",
       "0         0      0              0  ...         0              0          0   \n",
       "1         0      0              0  ...         0              0          0   \n",
       "2         0      0              2  ...         0              0          0   \n",
       "3         0      3              2  ...         0              2          0   \n",
       "4         0      0              1  ...         0              0          0   \n",
       "...     ...    ...            ...  ...       ...            ...        ...   \n",
       "3767      0      0              0  ...         0              0          0   \n",
       "3768      0      0              2  ...         0              0          0   \n",
       "3769      0      0              0  ...         0              0          0   \n",
       "3770      0     10              7  ...         0              0          0   \n",
       "3771      0      0              0  ...         0              0          0   \n",
       "\n",
       "      nb_space  nb_www  nb_com  nb_dslash  http_in_path  nb_subdomains  \\\n",
       "0            0       0       0          0             0              2   \n",
       "1            0       1       0          0             0              3   \n",
       "2            0       0       0          0             0              2   \n",
       "3            0       0       0          0             0              2   \n",
       "4            0       0       0          0             0              2   \n",
       "...        ...     ...     ...        ...           ...            ...   \n",
       "3767         0       1       0          0             0              2   \n",
       "3768         0       0       0          0             0              2   \n",
       "3769         0       1       0          0             0              2   \n",
       "3770         1       0       1          0             1              3   \n",
       "3771         0       0       0          0             0              1   \n",
       "\n",
       "          status  \n",
       "0       phishing  \n",
       "1     legitimate  \n",
       "2     legitimate  \n",
       "3       phishing  \n",
       "4     legitimate  \n",
       "...          ...  \n",
       "3767  legitimate  \n",
       "3768  legitimate  \n",
       "3769  legitimate  \n",
       "3770  legitimate  \n",
       "3771    phishing  \n",
       "\n",
       "[3772 rows x 25 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_keep = [\"length_url\", \"length_hostname\", \"nb_dots\", \"nb_hyphens\", \"nb_at\", \"nb_qm\", \n",
    "                \"nb_and\", \"nb_or\", \"nb_eq\", \"nb_underscore\", \"nb_tilde\", \"nb_percent\", \"nb_slash\", \n",
    "                \"nb_star\", \"nb_colon\", \"nb_comma\", \"nb_semicolumn\", \"nb_dollar\", \"nb_space\", \"nb_www\", \n",
    "                \"nb_com\", \"nb_dslash\", \"http_in_path\", \"nb_subdomains\", \"status\"]\n",
    "\n",
    "# Filter out columns not present in the column_names list\n",
    "columns_to_keep = [col for col in df.columns if col in cols_to_keep]\n",
    "\n",
    "# Drop columns not present in the column_names list\n",
    "df = df[cols_to_keep]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e04c2be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length_url</th>\n",
       "      <th>length_hostname</th>\n",
       "      <th>nb_dots</th>\n",
       "      <th>nb_hyphens</th>\n",
       "      <th>nb_at</th>\n",
       "      <th>nb_qm</th>\n",
       "      <th>nb_and</th>\n",
       "      <th>nb_or</th>\n",
       "      <th>nb_eq</th>\n",
       "      <th>nb_underscore</th>\n",
       "      <th>...</th>\n",
       "      <th>nb_colon</th>\n",
       "      <th>nb_comma</th>\n",
       "      <th>nb_semicolumn</th>\n",
       "      <th>nb_dollar</th>\n",
       "      <th>nb_space</th>\n",
       "      <th>nb_www</th>\n",
       "      <th>nb_com</th>\n",
       "      <th>nb_dslash</th>\n",
       "      <th>http_in_path</th>\n",
       "      <th>nb_subdomains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>185</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3767</th>\n",
       "      <td>34</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3768</th>\n",
       "      <td>54</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3769</th>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>550</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>77</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3772 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      length_url  length_hostname  nb_dots  nb_hyphens  nb_at  nb_qm  nb_and  \\\n",
       "0             36               19        2           0      0      0       0   \n",
       "1             51               24        3           0      0      0       0   \n",
       "2             46               16        2           0      0      0       0   \n",
       "3            185               17        2           1      0      1       2   \n",
       "4             52               16        2           0      0      0       0   \n",
       "...          ...              ...      ...         ...    ...    ...     ...   \n",
       "3767          34               26        2           0      0      0       0   \n",
       "3768          54               14        2           0      0      0       0   \n",
       "3769          25               16        2           0      0      0       0   \n",
       "3770         550               25        5          24      0      1       9   \n",
       "3771          77               23        1           0      0      0       0   \n",
       "\n",
       "      nb_or  nb_eq  nb_underscore  ...  nb_colon  nb_comma  nb_semicolumn  \\\n",
       "0         0      0              0  ...         1         0              0   \n",
       "1         0      0              0  ...         1         0              0   \n",
       "2         0      0              2  ...         1         0              0   \n",
       "3         0      3              2  ...         1         0              2   \n",
       "4         0      0              1  ...         1         0              0   \n",
       "...     ...    ...            ...  ...       ...       ...            ...   \n",
       "3767      0      0              0  ...         1         0              0   \n",
       "3768      0      0              2  ...         2         0              0   \n",
       "3769      0      0              0  ...         1         0              0   \n",
       "3770      0     10              7  ...         2         0              0   \n",
       "3771      0      0              0  ...         1         0              0   \n",
       "\n",
       "      nb_dollar  nb_space  nb_www  nb_com  nb_dslash  http_in_path  \\\n",
       "0             0         0       0       0          0             0   \n",
       "1             0         0       1       0          0             0   \n",
       "2             0         0       0       0          0             0   \n",
       "3             0         0       0       0          0             0   \n",
       "4             0         0       0       0          0             0   \n",
       "...         ...       ...     ...     ...        ...           ...   \n",
       "3767          0         0       1       0          0             0   \n",
       "3768          0         0       0       0          0             0   \n",
       "3769          0         0       1       0          0             0   \n",
       "3770          0         1       0       1          0             1   \n",
       "3771          0         0       0       0          0             0   \n",
       "\n",
       "      nb_subdomains  \n",
       "0                 2  \n",
       "1                 3  \n",
       "2                 2  \n",
       "3                 2  \n",
       "4                 2  \n",
       "...             ...  \n",
       "3767              2  \n",
       "3768              2  \n",
       "3769              2  \n",
       "3770              3  \n",
       "3771              1  \n",
       "\n",
       "[3772 rows x 24 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select our target variable\n",
    "target_variable = 'status'\n",
    "\n",
    "X_target = df.drop([target_variable], axis=1)\n",
    "\n",
    "y = df[target_variable]\n",
    "df.drop([target_variable], inplace=True, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82eb1c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length_url</th>\n",
       "      <th>length_hostname</th>\n",
       "      <th>nb_dots</th>\n",
       "      <th>nb_hyphens</th>\n",
       "      <th>nb_at</th>\n",
       "      <th>nb_qm</th>\n",
       "      <th>nb_and</th>\n",
       "      <th>nb_or</th>\n",
       "      <th>nb_eq</th>\n",
       "      <th>nb_underscore</th>\n",
       "      <th>...</th>\n",
       "      <th>nb_colon</th>\n",
       "      <th>nb_comma</th>\n",
       "      <th>nb_semicolumn</th>\n",
       "      <th>nb_dollar</th>\n",
       "      <th>nb_space</th>\n",
       "      <th>nb_www</th>\n",
       "      <th>nb_com</th>\n",
       "      <th>nb_dslash</th>\n",
       "      <th>http_in_path</th>\n",
       "      <th>nb_subdomains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.530043</td>\n",
       "      <td>-0.192143</td>\n",
       "      <td>-0.374353</td>\n",
       "      <td>-0.458789</td>\n",
       "      <td>-0.151506</td>\n",
       "      <td>-0.384054</td>\n",
       "      <td>-0.211981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.307427</td>\n",
       "      <td>-0.302916</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113788</td>\n",
       "      <td>-0.036066</td>\n",
       "      <td>-0.110157</td>\n",
       "      <td>-0.030908</td>\n",
       "      <td>-0.117777</td>\n",
       "      <td>-0.887584</td>\n",
       "      <td>-0.35201</td>\n",
       "      <td>-0.080021</td>\n",
       "      <td>-0.092661</td>\n",
       "      <td>-0.389207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.216023</td>\n",
       "      <td>0.229918</td>\n",
       "      <td>0.365720</td>\n",
       "      <td>-0.458789</td>\n",
       "      <td>-0.151506</td>\n",
       "      <td>-0.384054</td>\n",
       "      <td>-0.211981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.307427</td>\n",
       "      <td>-0.302916</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113788</td>\n",
       "      <td>-0.036066</td>\n",
       "      <td>-0.110157</td>\n",
       "      <td>-0.030908</td>\n",
       "      <td>-0.117777</td>\n",
       "      <td>1.107629</td>\n",
       "      <td>-0.35201</td>\n",
       "      <td>-0.080021</td>\n",
       "      <td>-0.092661</td>\n",
       "      <td>1.182621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.320696</td>\n",
       "      <td>-0.445380</td>\n",
       "      <td>-0.374353</td>\n",
       "      <td>-0.458789</td>\n",
       "      <td>-0.151506</td>\n",
       "      <td>-0.384054</td>\n",
       "      <td>-0.211981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.307427</td>\n",
       "      <td>1.650244</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113788</td>\n",
       "      <td>-0.036066</td>\n",
       "      <td>-0.110157</td>\n",
       "      <td>-0.030908</td>\n",
       "      <td>-0.117777</td>\n",
       "      <td>-0.887584</td>\n",
       "      <td>-0.35201</td>\n",
       "      <td>-0.080021</td>\n",
       "      <td>-0.092661</td>\n",
       "      <td>-0.389207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.589220</td>\n",
       "      <td>-0.360967</td>\n",
       "      <td>-0.374353</td>\n",
       "      <td>0.006538</td>\n",
       "      <td>-0.151506</td>\n",
       "      <td>2.391141</td>\n",
       "      <td>2.310396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.843696</td>\n",
       "      <td>1.650244</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113788</td>\n",
       "      <td>-0.036066</td>\n",
       "      <td>3.227304</td>\n",
       "      <td>-0.030908</td>\n",
       "      <td>-0.117777</td>\n",
       "      <td>-0.887584</td>\n",
       "      <td>-0.35201</td>\n",
       "      <td>-0.080021</td>\n",
       "      <td>-0.092661</td>\n",
       "      <td>-0.389207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.195088</td>\n",
       "      <td>-0.445380</td>\n",
       "      <td>-0.374353</td>\n",
       "      <td>-0.458789</td>\n",
       "      <td>-0.151506</td>\n",
       "      <td>-0.384054</td>\n",
       "      <td>-0.211981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.307427</td>\n",
       "      <td>0.673664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113788</td>\n",
       "      <td>-0.036066</td>\n",
       "      <td>-0.110157</td>\n",
       "      <td>-0.030908</td>\n",
       "      <td>-0.117777</td>\n",
       "      <td>-0.887584</td>\n",
       "      <td>-0.35201</td>\n",
       "      <td>-0.080021</td>\n",
       "      <td>-0.092661</td>\n",
       "      <td>-0.389207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3767</th>\n",
       "      <td>-0.571912</td>\n",
       "      <td>0.398743</td>\n",
       "      <td>-0.374353</td>\n",
       "      <td>-0.458789</td>\n",
       "      <td>-0.151506</td>\n",
       "      <td>-0.384054</td>\n",
       "      <td>-0.211981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.307427</td>\n",
       "      <td>-0.302916</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113788</td>\n",
       "      <td>-0.036066</td>\n",
       "      <td>-0.110157</td>\n",
       "      <td>-0.030908</td>\n",
       "      <td>-0.117777</td>\n",
       "      <td>1.107629</td>\n",
       "      <td>-0.35201</td>\n",
       "      <td>-0.080021</td>\n",
       "      <td>-0.092661</td>\n",
       "      <td>-0.389207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3768</th>\n",
       "      <td>-0.153219</td>\n",
       "      <td>-0.614204</td>\n",
       "      <td>-0.374353</td>\n",
       "      <td>-0.458789</td>\n",
       "      <td>-0.151506</td>\n",
       "      <td>-0.384054</td>\n",
       "      <td>-0.211981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.307427</td>\n",
       "      <td>1.650244</td>\n",
       "      <td>...</td>\n",
       "      <td>4.655183</td>\n",
       "      <td>-0.036066</td>\n",
       "      <td>-0.110157</td>\n",
       "      <td>-0.030908</td>\n",
       "      <td>-0.117777</td>\n",
       "      <td>-0.887584</td>\n",
       "      <td>-0.35201</td>\n",
       "      <td>-0.080021</td>\n",
       "      <td>-0.092661</td>\n",
       "      <td>-0.389207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3769</th>\n",
       "      <td>-0.760324</td>\n",
       "      <td>-0.445380</td>\n",
       "      <td>-0.374353</td>\n",
       "      <td>-0.458789</td>\n",
       "      <td>-0.151506</td>\n",
       "      <td>-0.384054</td>\n",
       "      <td>-0.211981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.307427</td>\n",
       "      <td>-0.302916</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113788</td>\n",
       "      <td>-0.036066</td>\n",
       "      <td>-0.110157</td>\n",
       "      <td>-0.030908</td>\n",
       "      <td>-0.117777</td>\n",
       "      <td>1.107629</td>\n",
       "      <td>-0.35201</td>\n",
       "      <td>-0.080021</td>\n",
       "      <td>-0.092661</td>\n",
       "      <td>-0.389207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>10.230366</td>\n",
       "      <td>0.314330</td>\n",
       "      <td>1.845867</td>\n",
       "      <td>10.709067</td>\n",
       "      <td>-0.151506</td>\n",
       "      <td>2.391141</td>\n",
       "      <td>11.138717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.196315</td>\n",
       "      <td>6.533142</td>\n",
       "      <td>...</td>\n",
       "      <td>4.655183</td>\n",
       "      <td>-0.036066</td>\n",
       "      <td>-0.110157</td>\n",
       "      <td>-0.030908</td>\n",
       "      <td>2.495487</td>\n",
       "      <td>-0.887584</td>\n",
       "      <td>2.36329</td>\n",
       "      <td>-0.080021</td>\n",
       "      <td>6.760640</td>\n",
       "      <td>1.182621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>0.328278</td>\n",
       "      <td>0.145506</td>\n",
       "      <td>-1.114427</td>\n",
       "      <td>-0.458789</td>\n",
       "      <td>-0.151506</td>\n",
       "      <td>-0.384054</td>\n",
       "      <td>-0.211981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.307427</td>\n",
       "      <td>-0.302916</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113788</td>\n",
       "      <td>-0.036066</td>\n",
       "      <td>-0.110157</td>\n",
       "      <td>-0.030908</td>\n",
       "      <td>-0.117777</td>\n",
       "      <td>-0.887584</td>\n",
       "      <td>-0.35201</td>\n",
       "      <td>-0.080021</td>\n",
       "      <td>-0.092661</td>\n",
       "      <td>-1.961034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3772 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      length_url  length_hostname   nb_dots  nb_hyphens     nb_at     nb_qm  \\\n",
       "0      -0.530043        -0.192143 -0.374353   -0.458789 -0.151506 -0.384054   \n",
       "1      -0.216023         0.229918  0.365720   -0.458789 -0.151506 -0.384054   \n",
       "2      -0.320696        -0.445380 -0.374353   -0.458789 -0.151506 -0.384054   \n",
       "3       2.589220        -0.360967 -0.374353    0.006538 -0.151506  2.391141   \n",
       "4      -0.195088        -0.445380 -0.374353   -0.458789 -0.151506 -0.384054   \n",
       "...          ...              ...       ...         ...       ...       ...   \n",
       "3767   -0.571912         0.398743 -0.374353   -0.458789 -0.151506 -0.384054   \n",
       "3768   -0.153219        -0.614204 -0.374353   -0.458789 -0.151506 -0.384054   \n",
       "3769   -0.760324        -0.445380 -0.374353   -0.458789 -0.151506 -0.384054   \n",
       "3770   10.230366         0.314330  1.845867   10.709067 -0.151506  2.391141   \n",
       "3771    0.328278         0.145506 -1.114427   -0.458789 -0.151506 -0.384054   \n",
       "\n",
       "         nb_and  nb_or      nb_eq  nb_underscore  ...  nb_colon  nb_comma  \\\n",
       "0     -0.211981    0.0  -0.307427      -0.302916  ... -0.113788 -0.036066   \n",
       "1     -0.211981    0.0  -0.307427      -0.302916  ... -0.113788 -0.036066   \n",
       "2     -0.211981    0.0  -0.307427       1.650244  ... -0.113788 -0.036066   \n",
       "3      2.310396    0.0   2.843696       1.650244  ... -0.113788 -0.036066   \n",
       "4     -0.211981    0.0  -0.307427       0.673664  ... -0.113788 -0.036066   \n",
       "...         ...    ...        ...            ...  ...       ...       ...   \n",
       "3767  -0.211981    0.0  -0.307427      -0.302916  ... -0.113788 -0.036066   \n",
       "3768  -0.211981    0.0  -0.307427       1.650244  ...  4.655183 -0.036066   \n",
       "3769  -0.211981    0.0  -0.307427      -0.302916  ... -0.113788 -0.036066   \n",
       "3770  11.138717    0.0  10.196315       6.533142  ...  4.655183 -0.036066   \n",
       "3771  -0.211981    0.0  -0.307427      -0.302916  ... -0.113788 -0.036066   \n",
       "\n",
       "      nb_semicolumn  nb_dollar  nb_space    nb_www   nb_com  nb_dslash  \\\n",
       "0         -0.110157  -0.030908 -0.117777 -0.887584 -0.35201  -0.080021   \n",
       "1         -0.110157  -0.030908 -0.117777  1.107629 -0.35201  -0.080021   \n",
       "2         -0.110157  -0.030908 -0.117777 -0.887584 -0.35201  -0.080021   \n",
       "3          3.227304  -0.030908 -0.117777 -0.887584 -0.35201  -0.080021   \n",
       "4         -0.110157  -0.030908 -0.117777 -0.887584 -0.35201  -0.080021   \n",
       "...             ...        ...       ...       ...      ...        ...   \n",
       "3767      -0.110157  -0.030908 -0.117777  1.107629 -0.35201  -0.080021   \n",
       "3768      -0.110157  -0.030908 -0.117777 -0.887584 -0.35201  -0.080021   \n",
       "3769      -0.110157  -0.030908 -0.117777  1.107629 -0.35201  -0.080021   \n",
       "3770      -0.110157  -0.030908  2.495487 -0.887584  2.36329  -0.080021   \n",
       "3771      -0.110157  -0.030908 -0.117777 -0.887584 -0.35201  -0.080021   \n",
       "\n",
       "      http_in_path  nb_subdomains  \n",
       "0        -0.092661      -0.389207  \n",
       "1        -0.092661       1.182621  \n",
       "2        -0.092661      -0.389207  \n",
       "3        -0.092661      -0.389207  \n",
       "4        -0.092661      -0.389207  \n",
       "...            ...            ...  \n",
       "3767     -0.092661      -0.389207  \n",
       "3768     -0.092661      -0.389207  \n",
       "3769     -0.092661      -0.389207  \n",
       "3770      6.760640       1.182621  \n",
       "3771     -0.092661      -1.961034  \n",
       "\n",
       "[3772 rows x 24 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(df)\n",
    "df_scaled = pd.DataFrame(data=X, columns=df.columns)\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7db19a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)\n",
    "\n",
    "# encode the training sets\n",
    "y_train = (y_train == 'legitimate').astype(int)\n",
    "y_test = (y_test == 'legitimate').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab520407",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "fnn_model = Sequential()\n",
    "\n",
    "# input layer neruons count equal to number of features and ReLU activation\n",
    "input_layer = Dense(X_train.shape[1], input_dim=X_train.shape[1], activation='relu')\n",
    "\n",
    "# hidden layer with 64 neurons for the first, and 32 for the second, and ReLU activation\n",
    "hidden_layer_one = Dense(64, activation = 'relu')\n",
    "hidden_layer_two = Dense(32, activation = 'relu')\n",
    "\n",
    "# output layer with 1 neuron and sigmoid activation (binary classification)\n",
    "output_layer = Dense(1, activation='sigmoid')\n",
    "\n",
    "# add the layers to the model\n",
    "fnn_model.add(input_layer)\n",
    "fnn_model.add(hidden_layer_one)\n",
    "fnn_model.add(hidden_layer_two)\n",
    "fnn_model.add(output_layer)\n",
    "\n",
    "# compile the model\n",
    "fnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "981bad84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6913 - loss: 0.6127 - val_accuracy: 0.7959 - val_loss: 0.4419\n",
      "Epoch 2/10\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.8023 - loss: 0.4285 - val_accuracy: 0.8004 - val_loss: 0.4137\n",
      "Epoch 3/10\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.8106 - loss: 0.3999 - val_accuracy: 0.8065 - val_loss: 0.4029\n",
      "Epoch 4/10\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.8225 - loss: 0.3741 - val_accuracy: 0.8030 - val_loss: 0.4042\n",
      "Epoch 5/10\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.8208 - loss: 0.3924 - val_accuracy: 0.8057 - val_loss: 0.4001\n",
      "Epoch 6/10\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.8315 - loss: 0.3678 - val_accuracy: 0.8083 - val_loss: 0.3988\n",
      "Epoch 7/10\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.8411 - loss: 0.3625 - val_accuracy: 0.8074 - val_loss: 0.3982\n",
      "Epoch 8/10\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.8458 - loss: 0.3485 - val_accuracy: 0.8118 - val_loss: 0.3966\n",
      "Epoch 9/10\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.8382 - loss: 0.3580 - val_accuracy: 0.8065 - val_loss: 0.4142\n",
      "Epoch 10/10\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.8299 - loss: 0.3669 - val_accuracy: 0.8145 - val_loss: 0.3991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2cd6a9a2af0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1195e74",
   "metadata": {},
   "source": [
    "We can already see that our accuracy is much lower than our previous model. However, we can train our model for more epochs to improve it's accuracy. Let's rerun our model for longer and see how this improves our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03a80fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnn_model = Sequential()\n",
    "\n",
    "# input layer neruons count equal to number of features and ReLU activation\n",
    "input_layer = Dense(X_train.shape[1], input_dim=X_train.shape[1], activation='relu')\n",
    "\n",
    "# hidden layer with 64 neurons for the first, and 32 for the second, and ReLU activation\n",
    "hidden_layer_one = Dense(64, activation = 'relu')\n",
    "hidden_layer_two = Dense(32, activation = 'relu')\n",
    "\n",
    "# output layer with 1 neuron and sigmoid activation (binary classification)\n",
    "output_layer = Dense(1, activation='sigmoid')\n",
    "\n",
    "# add the layers to the model\n",
    "fnn_model.add(input_layer)\n",
    "fnn_model.add(hidden_layer_one)\n",
    "fnn_model.add(hidden_layer_two)\n",
    "fnn_model.add(output_layer)\n",
    "\n",
    "# compile the model\n",
    "fnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff190e81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6916 - loss: 0.6155 - val_accuracy: 0.7588 - val_loss: 0.4870\n",
      "Epoch 2/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.7919 - loss: 0.4505 - val_accuracy: 0.7995 - val_loss: 0.4408\n",
      "Epoch 3/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.8140 - loss: 0.4032 - val_accuracy: 0.8057 - val_loss: 0.4202\n",
      "Epoch 4/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.8323 - loss: 0.3881 - val_accuracy: 0.8083 - val_loss: 0.4166\n",
      "Epoch 5/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.8224 - loss: 0.3827 - val_accuracy: 0.8127 - val_loss: 0.4048\n",
      "Epoch 6/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.8334 - loss: 0.3677 - val_accuracy: 0.8057 - val_loss: 0.4114\n",
      "Epoch 7/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.8297 - loss: 0.3619 - val_accuracy: 0.8127 - val_loss: 0.4018\n",
      "Epoch 8/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.8470 - loss: 0.3416 - val_accuracy: 0.8092 - val_loss: 0.4053\n",
      "Epoch 9/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.8322 - loss: 0.3611 - val_accuracy: 0.8057 - val_loss: 0.4008\n",
      "Epoch 10/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.8457 - loss: 0.3363 - val_accuracy: 0.8118 - val_loss: 0.3978\n",
      "Epoch 11/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.8465 - loss: 0.3375 - val_accuracy: 0.8118 - val_loss: 0.4003\n",
      "Epoch 12/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.8467 - loss: 0.3386 - val_accuracy: 0.8171 - val_loss: 0.3928\n",
      "Epoch 13/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.8444 - loss: 0.3282 - val_accuracy: 0.8145 - val_loss: 0.4023\n",
      "Epoch 14/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.8452 - loss: 0.3404 - val_accuracy: 0.8224 - val_loss: 0.3919\n",
      "Epoch 15/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.8508 - loss: 0.3305 - val_accuracy: 0.8171 - val_loss: 0.3936\n",
      "Epoch 16/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.8466 - loss: 0.3306 - val_accuracy: 0.8260 - val_loss: 0.3912\n",
      "Epoch 17/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.8580 - loss: 0.3145 - val_accuracy: 0.8189 - val_loss: 0.3911\n",
      "Epoch 18/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.8588 - loss: 0.3134 - val_accuracy: 0.8136 - val_loss: 0.4033\n",
      "Epoch 19/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.8383 - loss: 0.3355 - val_accuracy: 0.8224 - val_loss: 0.3922\n",
      "Epoch 20/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.8628 - loss: 0.3114 - val_accuracy: 0.8313 - val_loss: 0.3854\n",
      "Epoch 21/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.8543 - loss: 0.3131 - val_accuracy: 0.8313 - val_loss: 0.3926\n",
      "Epoch 22/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.8558 - loss: 0.3093 - val_accuracy: 0.8242 - val_loss: 0.3840\n",
      "Epoch 23/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.8664 - loss: 0.3002 - val_accuracy: 0.8269 - val_loss: 0.3887\n",
      "Epoch 24/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.8594 - loss: 0.3074 - val_accuracy: 0.8277 - val_loss: 0.3856\n",
      "Epoch 25/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.8638 - loss: 0.2932 - val_accuracy: 0.8216 - val_loss: 0.3949\n",
      "Epoch 26/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.8617 - loss: 0.2987 - val_accuracy: 0.8304 - val_loss: 0.3886\n",
      "Epoch 27/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.8718 - loss: 0.2794 - val_accuracy: 0.8322 - val_loss: 0.3900\n",
      "Epoch 28/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.8609 - loss: 0.3093 - val_accuracy: 0.8277 - val_loss: 0.4106\n",
      "Epoch 29/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.8600 - loss: 0.3003 - val_accuracy: 0.8348 - val_loss: 0.3975\n",
      "Epoch 30/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.8764 - loss: 0.2824 - val_accuracy: 0.8286 - val_loss: 0.3906\n",
      "Epoch 31/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.8542 - loss: 0.3085 - val_accuracy: 0.8313 - val_loss: 0.3963\n",
      "Epoch 32/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.8806 - loss: 0.2759 - val_accuracy: 0.8375 - val_loss: 0.3941\n",
      "Epoch 33/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.8788 - loss: 0.2912 - val_accuracy: 0.8313 - val_loss: 0.3960\n",
      "Epoch 34/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.8638 - loss: 0.3021 - val_accuracy: 0.8357 - val_loss: 0.3940\n",
      "Epoch 35/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - accuracy: 0.8759 - loss: 0.2851 - val_accuracy: 0.8295 - val_loss: 0.4086\n",
      "Epoch 36/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.8656 - loss: 0.2939 - val_accuracy: 0.8357 - val_loss: 0.3948\n",
      "Epoch 37/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.8694 - loss: 0.2939 - val_accuracy: 0.8383 - val_loss: 0.3972\n",
      "Epoch 38/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.8693 - loss: 0.2922 - val_accuracy: 0.8251 - val_loss: 0.3976\n",
      "Epoch 39/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.8811 - loss: 0.2776 - val_accuracy: 0.8233 - val_loss: 0.3959\n",
      "Epoch 40/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.8678 - loss: 0.2876 - val_accuracy: 0.8322 - val_loss: 0.4059\n",
      "Epoch 41/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.8806 - loss: 0.2725 - val_accuracy: 0.8304 - val_loss: 0.4136\n",
      "Epoch 42/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.8794 - loss: 0.2682 - val_accuracy: 0.8322 - val_loss: 0.4086\n",
      "Epoch 43/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.8854 - loss: 0.2643 - val_accuracy: 0.8375 - val_loss: 0.4060\n",
      "Epoch 44/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.8841 - loss: 0.2631 - val_accuracy: 0.8286 - val_loss: 0.4184\n",
      "Epoch 45/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.8756 - loss: 0.2774 - val_accuracy: 0.8330 - val_loss: 0.4043\n",
      "Epoch 46/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.8716 - loss: 0.2750 - val_accuracy: 0.8375 - val_loss: 0.3994\n",
      "Epoch 47/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.8700 - loss: 0.2696 - val_accuracy: 0.8313 - val_loss: 0.4110\n",
      "Epoch 48/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.8866 - loss: 0.2573 - val_accuracy: 0.8410 - val_loss: 0.3994\n",
      "Epoch 49/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.8819 - loss: 0.2597 - val_accuracy: 0.8339 - val_loss: 0.4089\n",
      "Epoch 50/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.8827 - loss: 0.2524 - val_accuracy: 0.8357 - val_loss: 0.4101\n",
      "Epoch 51/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.8805 - loss: 0.2621 - val_accuracy: 0.8366 - val_loss: 0.4125\n",
      "Epoch 52/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.8706 - loss: 0.2724 - val_accuracy: 0.8313 - val_loss: 0.4261\n",
      "Epoch 53/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.8839 - loss: 0.2457 - val_accuracy: 0.8295 - val_loss: 0.4162\n",
      "Epoch 54/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.8914 - loss: 0.2591 - val_accuracy: 0.8419 - val_loss: 0.4126\n",
      "Epoch 55/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.8797 - loss: 0.2610 - val_accuracy: 0.8304 - val_loss: 0.4220\n",
      "Epoch 56/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.8716 - loss: 0.2571 - val_accuracy: 0.8339 - val_loss: 0.4171\n",
      "Epoch 57/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.8796 - loss: 0.2602 - val_accuracy: 0.8233 - val_loss: 0.4277\n",
      "Epoch 58/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.8853 - loss: 0.2565 - val_accuracy: 0.8401 - val_loss: 0.4287\n",
      "Epoch 59/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.8811 - loss: 0.2613 - val_accuracy: 0.8260 - val_loss: 0.4249\n",
      "Epoch 60/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.8910 - loss: 0.2415 - val_accuracy: 0.8224 - val_loss: 0.4330\n",
      "Epoch 61/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.8806 - loss: 0.2515 - val_accuracy: 0.8260 - val_loss: 0.4455\n",
      "Epoch 62/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.8885 - loss: 0.2483 - val_accuracy: 0.8224 - val_loss: 0.4402\n",
      "Epoch 63/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.8848 - loss: 0.2472 - val_accuracy: 0.8216 - val_loss: 0.4563\n",
      "Epoch 64/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.8941 - loss: 0.2437 - val_accuracy: 0.8330 - val_loss: 0.4346\n",
      "Epoch 65/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.8860 - loss: 0.2451 - val_accuracy: 0.8383 - val_loss: 0.4338\n",
      "Epoch 66/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.8941 - loss: 0.2409 - val_accuracy: 0.8286 - val_loss: 0.4309\n",
      "Epoch 67/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.9006 - loss: 0.2376 - val_accuracy: 0.8339 - val_loss: 0.4445\n",
      "Epoch 68/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.8945 - loss: 0.2367 - val_accuracy: 0.8286 - val_loss: 0.4527\n",
      "Epoch 69/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.9038 - loss: 0.2315 - val_accuracy: 0.8313 - val_loss: 0.4452\n",
      "Epoch 70/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.8908 - loss: 0.2404 - val_accuracy: 0.8251 - val_loss: 0.4385\n",
      "Epoch 71/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.8805 - loss: 0.2507 - val_accuracy: 0.8366 - val_loss: 0.4309\n",
      "Epoch 72/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.8961 - loss: 0.2309 - val_accuracy: 0.8330 - val_loss: 0.4563\n",
      "Epoch 73/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.8952 - loss: 0.2399 - val_accuracy: 0.8313 - val_loss: 0.4614\n",
      "Epoch 74/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.8846 - loss: 0.2521 - val_accuracy: 0.8269 - val_loss: 0.4770\n",
      "Epoch 75/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.8899 - loss: 0.2296 - val_accuracy: 0.8216 - val_loss: 0.4526\n",
      "Epoch 76/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.8906 - loss: 0.2429 - val_accuracy: 0.8392 - val_loss: 0.4607\n",
      "Epoch 77/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.8877 - loss: 0.2630 - val_accuracy: 0.8171 - val_loss: 0.4516\n",
      "Epoch 78/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.8902 - loss: 0.2351 - val_accuracy: 0.8339 - val_loss: 0.4430\n",
      "Epoch 79/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.8946 - loss: 0.2356 - val_accuracy: 0.8357 - val_loss: 0.4481\n",
      "Epoch 80/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.9001 - loss: 0.2198 - val_accuracy: 0.8277 - val_loss: 0.4638\n",
      "Epoch 81/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.8997 - loss: 0.2353 - val_accuracy: 0.8260 - val_loss: 0.4522\n",
      "Epoch 82/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.8947 - loss: 0.2338 - val_accuracy: 0.8216 - val_loss: 0.4540\n",
      "Epoch 83/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.8910 - loss: 0.2334 - val_accuracy: 0.8224 - val_loss: 0.4609\n",
      "Epoch 84/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.9019 - loss: 0.2193 - val_accuracy: 0.8269 - val_loss: 0.4629\n",
      "Epoch 85/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.8961 - loss: 0.2366 - val_accuracy: 0.8198 - val_loss: 0.4531\n",
      "Epoch 86/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.8919 - loss: 0.2351 - val_accuracy: 0.8269 - val_loss: 0.4565\n",
      "Epoch 87/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.8919 - loss: 0.2394 - val_accuracy: 0.8313 - val_loss: 0.4741\n",
      "Epoch 88/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.8931 - loss: 0.2318 - val_accuracy: 0.8233 - val_loss: 0.4856\n",
      "Epoch 89/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8963 - loss: 0.2348 - val_accuracy: 0.8322 - val_loss: 0.4623\n",
      "Epoch 90/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.8993 - loss: 0.2221 - val_accuracy: 0.8189 - val_loss: 0.4716\n",
      "Epoch 91/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.8876 - loss: 0.2468 - val_accuracy: 0.8127 - val_loss: 0.4862\n",
      "Epoch 92/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.8830 - loss: 0.2401 - val_accuracy: 0.8269 - val_loss: 0.4913\n",
      "Epoch 93/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.9019 - loss: 0.2213 - val_accuracy: 0.8260 - val_loss: 0.4829\n",
      "Epoch 94/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.8935 - loss: 0.2223 - val_accuracy: 0.8251 - val_loss: 0.4744\n",
      "Epoch 95/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.8942 - loss: 0.2346 - val_accuracy: 0.8339 - val_loss: 0.4753\n",
      "Epoch 96/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.9045 - loss: 0.2123 - val_accuracy: 0.8277 - val_loss: 0.4927\n",
      "Epoch 97/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.8970 - loss: 0.2267 - val_accuracy: 0.8277 - val_loss: 0.4706\n",
      "Epoch 98/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.8916 - loss: 0.2274 - val_accuracy: 0.8224 - val_loss: 0.4929\n",
      "Epoch 99/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.8905 - loss: 0.2391 - val_accuracy: 0.8348 - val_loss: 0.4763\n",
      "Epoch 100/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.8974 - loss: 0.2148 - val_accuracy: 0.8242 - val_loss: 0.4912\n",
      "Epoch 101/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.8881 - loss: 0.2219 - val_accuracy: 0.8198 - val_loss: 0.4802\n",
      "Epoch 102/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.9045 - loss: 0.2027 - val_accuracy: 0.8322 - val_loss: 0.4878\n",
      "Epoch 103/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.9113 - loss: 0.2073 - val_accuracy: 0.8136 - val_loss: 0.5163\n",
      "Epoch 104/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.8952 - loss: 0.2285 - val_accuracy: 0.8366 - val_loss: 0.4840\n",
      "Epoch 105/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.9043 - loss: 0.2039 - val_accuracy: 0.8269 - val_loss: 0.5016\n",
      "Epoch 106/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.8953 - loss: 0.2238 - val_accuracy: 0.8260 - val_loss: 0.5027\n",
      "Epoch 107/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9080 - loss: 0.2119 - val_accuracy: 0.8198 - val_loss: 0.4843\n",
      "Epoch 108/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.8970 - loss: 0.2165 - val_accuracy: 0.8322 - val_loss: 0.4831\n",
      "Epoch 109/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.9030 - loss: 0.2178 - val_accuracy: 0.8242 - val_loss: 0.5226\n",
      "Epoch 110/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.9003 - loss: 0.2199 - val_accuracy: 0.8154 - val_loss: 0.4988\n",
      "Epoch 111/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.9009 - loss: 0.2047 - val_accuracy: 0.8277 - val_loss: 0.4964\n",
      "Epoch 112/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.8983 - loss: 0.2247 - val_accuracy: 0.8127 - val_loss: 0.5358\n",
      "Epoch 113/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.9050 - loss: 0.2120 - val_accuracy: 0.8224 - val_loss: 0.5140\n",
      "Epoch 114/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.9063 - loss: 0.2077 - val_accuracy: 0.8348 - val_loss: 0.4975\n",
      "Epoch 115/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.8955 - loss: 0.2255 - val_accuracy: 0.8269 - val_loss: 0.4957\n",
      "Epoch 116/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.9040 - loss: 0.2024 - val_accuracy: 0.8322 - val_loss: 0.5319\n",
      "Epoch 117/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.9073 - loss: 0.2079 - val_accuracy: 0.8295 - val_loss: 0.5175\n",
      "Epoch 118/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.9127 - loss: 0.2032 - val_accuracy: 0.8330 - val_loss: 0.5144\n",
      "Epoch 119/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.9065 - loss: 0.2032 - val_accuracy: 0.8375 - val_loss: 0.5167\n",
      "Epoch 120/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.9032 - loss: 0.2118 - val_accuracy: 0.8269 - val_loss: 0.5170\n",
      "Epoch 121/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.9036 - loss: 0.2067 - val_accuracy: 0.8383 - val_loss: 0.5309\n",
      "Epoch 122/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.8973 - loss: 0.2104 - val_accuracy: 0.8269 - val_loss: 0.5396\n",
      "Epoch 123/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9024 - loss: 0.2071 - val_accuracy: 0.8330 - val_loss: 0.5358\n",
      "Epoch 124/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9070 - loss: 0.1963 - val_accuracy: 0.8322 - val_loss: 0.5314\n",
      "Epoch 125/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.8981 - loss: 0.2190 - val_accuracy: 0.8189 - val_loss: 0.5238\n",
      "Epoch 126/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.9142 - loss: 0.1922 - val_accuracy: 0.8313 - val_loss: 0.5294\n",
      "Epoch 127/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.8984 - loss: 0.2088 - val_accuracy: 0.8322 - val_loss: 0.5179\n",
      "Epoch 128/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.9134 - loss: 0.1943 - val_accuracy: 0.8269 - val_loss: 0.5362\n",
      "Epoch 129/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.9043 - loss: 0.2130 - val_accuracy: 0.8304 - val_loss: 0.5336\n",
      "Epoch 130/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.9042 - loss: 0.2092 - val_accuracy: 0.8313 - val_loss: 0.5257\n",
      "Epoch 131/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.9070 - loss: 0.2039 - val_accuracy: 0.8322 - val_loss: 0.5187\n",
      "Epoch 132/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.9034 - loss: 0.2079 - val_accuracy: 0.8145 - val_loss: 0.5384\n",
      "Epoch 133/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.8971 - loss: 0.2142 - val_accuracy: 0.8277 - val_loss: 0.5462\n",
      "Epoch 134/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.9043 - loss: 0.2032 - val_accuracy: 0.8260 - val_loss: 0.5410\n",
      "Epoch 135/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9058 - loss: 0.2015 - val_accuracy: 0.8295 - val_loss: 0.5529\n",
      "Epoch 136/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9080 - loss: 0.2061 - val_accuracy: 0.8198 - val_loss: 0.5518\n",
      "Epoch 137/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.9125 - loss: 0.1952 - val_accuracy: 0.8163 - val_loss: 0.5479\n",
      "Epoch 138/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.9069 - loss: 0.1962 - val_accuracy: 0.8198 - val_loss: 0.5636\n",
      "Epoch 139/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.9136 - loss: 0.1964 - val_accuracy: 0.8277 - val_loss: 0.5354\n",
      "Epoch 140/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.8957 - loss: 0.2043 - val_accuracy: 0.8322 - val_loss: 0.5574\n",
      "Epoch 141/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.9095 - loss: 0.1966 - val_accuracy: 0.8242 - val_loss: 0.5456\n",
      "Epoch 142/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.9102 - loss: 0.2119 - val_accuracy: 0.8260 - val_loss: 0.5447\n",
      "Epoch 143/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.9030 - loss: 0.2148 - val_accuracy: 0.8286 - val_loss: 0.5596\n",
      "Epoch 144/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.9031 - loss: 0.2115 - val_accuracy: 0.8322 - val_loss: 0.5577\n",
      "Epoch 145/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.9035 - loss: 0.2089 - val_accuracy: 0.8313 - val_loss: 0.5812\n",
      "Epoch 146/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.9156 - loss: 0.1904 - val_accuracy: 0.8092 - val_loss: 0.6834\n",
      "Epoch 147/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.8838 - loss: 0.2648 - val_accuracy: 0.8295 - val_loss: 0.5499\n",
      "Epoch 148/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.9189 - loss: 0.2000 - val_accuracy: 0.8216 - val_loss: 0.5756\n",
      "Epoch 149/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.9098 - loss: 0.1936 - val_accuracy: 0.8233 - val_loss: 0.5810\n",
      "Epoch 150/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.9076 - loss: 0.1950 - val_accuracy: 0.8313 - val_loss: 0.5895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.9146 - loss: 0.1883 - val_accuracy: 0.8322 - val_loss: 0.5696\n",
      "Epoch 152/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9117 - loss: 0.2014 - val_accuracy: 0.8304 - val_loss: 0.5729\n",
      "Epoch 153/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.9133 - loss: 0.1882 - val_accuracy: 0.8216 - val_loss: 0.5910\n",
      "Epoch 154/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.9166 - loss: 0.1822 - val_accuracy: 0.8286 - val_loss: 0.5932\n",
      "Epoch 155/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.9211 - loss: 0.1869 - val_accuracy: 0.8313 - val_loss: 0.5765\n",
      "Epoch 156/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.9241 - loss: 0.1778 - val_accuracy: 0.8171 - val_loss: 0.5895\n",
      "Epoch 157/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.9139 - loss: 0.1862 - val_accuracy: 0.8322 - val_loss: 0.5944\n",
      "Epoch 158/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.9037 - loss: 0.2034 - val_accuracy: 0.8277 - val_loss: 0.5951\n",
      "Epoch 159/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9145 - loss: 0.1866 - val_accuracy: 0.8304 - val_loss: 0.5694\n",
      "Epoch 160/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.9112 - loss: 0.1831 - val_accuracy: 0.8295 - val_loss: 0.6021\n",
      "Epoch 161/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.9138 - loss: 0.1915 - val_accuracy: 0.8286 - val_loss: 0.6003\n",
      "Epoch 162/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.9091 - loss: 0.1954 - val_accuracy: 0.8286 - val_loss: 0.6127\n",
      "Epoch 163/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.9086 - loss: 0.1892 - val_accuracy: 0.8216 - val_loss: 0.6046\n",
      "Epoch 164/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.9194 - loss: 0.1824 - val_accuracy: 0.8260 - val_loss: 0.6043\n",
      "Epoch 165/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.9159 - loss: 0.1926 - val_accuracy: 0.8277 - val_loss: 0.5965\n",
      "Epoch 166/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.9134 - loss: 0.1787 - val_accuracy: 0.8295 - val_loss: 0.6107\n",
      "Epoch 167/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.9224 - loss: 0.1768 - val_accuracy: 0.8269 - val_loss: 0.6151\n",
      "Epoch 168/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.9130 - loss: 0.1862 - val_accuracy: 0.8260 - val_loss: 0.5940\n",
      "Epoch 169/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9166 - loss: 0.1846 - val_accuracy: 0.8198 - val_loss: 0.5938\n",
      "Epoch 170/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.9170 - loss: 0.1819 - val_accuracy: 0.8233 - val_loss: 0.5929\n",
      "Epoch 171/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.9187 - loss: 0.1797 - val_accuracy: 0.8180 - val_loss: 0.5917\n",
      "Epoch 172/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.9187 - loss: 0.1847 - val_accuracy: 0.8313 - val_loss: 0.6041\n",
      "Epoch 173/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.9178 - loss: 0.1768 - val_accuracy: 0.8313 - val_loss: 0.6478\n",
      "Epoch 174/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.8978 - loss: 0.2092 - val_accuracy: 0.8224 - val_loss: 0.6183\n",
      "Epoch 175/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.9153 - loss: 0.1905 - val_accuracy: 0.8322 - val_loss: 0.6091\n",
      "Epoch 176/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.9125 - loss: 0.1832 - val_accuracy: 0.8313 - val_loss: 0.6424\n",
      "Epoch 177/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.9143 - loss: 0.1832 - val_accuracy: 0.8207 - val_loss: 0.6168\n",
      "Epoch 178/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.9113 - loss: 0.1919 - val_accuracy: 0.8295 - val_loss: 0.6166\n",
      "Epoch 179/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.9215 - loss: 0.1748 - val_accuracy: 0.8286 - val_loss: 0.6293\n",
      "Epoch 180/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.9170 - loss: 0.1843 - val_accuracy: 0.8330 - val_loss: 0.6206\n",
      "Epoch 181/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.9195 - loss: 0.1814 - val_accuracy: 0.8357 - val_loss: 0.6129\n",
      "Epoch 182/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.9204 - loss: 0.1852 - val_accuracy: 0.8304 - val_loss: 0.6148\n",
      "Epoch 183/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.9040 - loss: 0.2030 - val_accuracy: 0.8260 - val_loss: 0.6242\n",
      "Epoch 184/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9184 - loss: 0.1838 - val_accuracy: 0.8366 - val_loss: 0.6252\n",
      "Epoch 185/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.9163 - loss: 0.1770 - val_accuracy: 0.8233 - val_loss: 0.6253\n",
      "Epoch 186/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.9143 - loss: 0.1880 - val_accuracy: 0.8375 - val_loss: 0.6295\n",
      "Epoch 187/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.9171 - loss: 0.1780 - val_accuracy: 0.8207 - val_loss: 0.6338\n",
      "Epoch 188/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.9212 - loss: 0.1709 - val_accuracy: 0.8295 - val_loss: 0.6352\n",
      "Epoch 189/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9240 - loss: 0.1780 - val_accuracy: 0.8260 - val_loss: 0.6433\n",
      "Epoch 190/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.9187 - loss: 0.1773 - val_accuracy: 0.8260 - val_loss: 0.6514\n",
      "Epoch 191/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.9168 - loss: 0.1827 - val_accuracy: 0.8383 - val_loss: 0.6284\n",
      "Epoch 192/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9250 - loss: 0.1653 - val_accuracy: 0.8224 - val_loss: 0.6416\n",
      "Epoch 193/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9141 - loss: 0.1821 - val_accuracy: 0.8171 - val_loss: 0.6320\n",
      "Epoch 194/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9144 - loss: 0.1858 - val_accuracy: 0.8171 - val_loss: 0.6716\n",
      "Epoch 195/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.9224 - loss: 0.1682 - val_accuracy: 0.8198 - val_loss: 0.6957\n",
      "Epoch 196/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.9160 - loss: 0.1925 - val_accuracy: 0.8313 - val_loss: 0.6609\n",
      "Epoch 197/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9229 - loss: 0.1800 - val_accuracy: 0.8322 - val_loss: 0.6186\n",
      "Epoch 198/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9177 - loss: 0.1888 - val_accuracy: 0.8410 - val_loss: 0.6230\n",
      "Epoch 199/200\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.9122 - loss: 0.2138 - val_accuracy: 0.8286 - val_loss: 0.6111\n",
      "Epoch 200/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/83\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0878\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.9293 - loss: 0.1723 - val_accuracy: 0.8092 - val_loss: 0.6023\n"
     ]
    }
   ],
   "source": [
    "history = fnn_model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fce9cc9",
   "metadata": {},
   "source": [
    "Running our model for 200 epochs has yielded us an extra 6% in accuracy, bridging the gap between our model with fewer attributes, and our model with more attributes. This means that we can have a model with similar performance and less inputs at the cost of a longer training period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74f9d9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract accuracy values from the training history\n",
    "train_accuracy = history.history['accuracy']\n",
    "\n",
    "# Fit a polynomial curve to the training accuracy data points\n",
    "fit_coefficients = np.polyfit(epochs, train_accuracy, 4)\n",
    "fit_curve = np.poly1d(fit_coefficients)\n",
    "\n",
    "# Plot the accuracy over epochs\n",
    "epochs = range(1, len(train_accuracy) + 1)\n",
    "plt.plot(epochs, train_accuracy, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs, fit_curve(epochs), color='red', linestyle='--', label='Curve of Best Fit')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dfd8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = fnn_model.predict(X_test)\n",
    "y_pred = (y_pred >= 0.5).astype(int) # round probabilities to get binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bab4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = fnn_model.predict(X_train)\n",
    "y_pred_train = (y_pred_train >= 0.5).astype(int) # round probabilities to get binary labels\n",
    "    \n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83856e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the most frequent value\n",
    "most_frequent = (y_test == 0).sum() if (y_test == 0).sum() >= (y_test == 1).sum() else (y_test == 1).sum()\n",
    "\n",
    "null_accuracy = most_frequent/len(y_test)\n",
    "print('Null accuracy score: {0:0.4f}'. format(null_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b2d86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "\n",
    "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
    "\n",
    "print('\\nFalse Negatives(FN) = ', cm[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6650ff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Phishing', 'Actual Legitimate'], \n",
    "                                 index=['Predict Phishing', 'Predict Legitimate'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e6b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8bc3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = cm[0,0]\n",
    "TN = cm[1,1]\n",
    "FP = cm[0,1]\n",
    "FN = cm[1,0]\n",
    "\n",
    "precision = TP / float(TP + FP)\n",
    "recall = TP / float(TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "negative_predictive_value = TN / (TN + FN)\n",
    "accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
    "f1_score = 2*((precision * recall) / (precision + recall))\n",
    "balanced_accuracy = (recall + specificity) / 2\n",
    "\n",
    "print('Accuracy : {0:0.4f}'.format(accuracy))\n",
    "print('Precision : {0:0.4f}'.format(precision))\n",
    "print('Recall: {0:0.4f}'.format(recall))\n",
    "print('Specificity : {0:0.4f}'.format(specificity))\n",
    "print('NPV: {0:0.4f}'.format(negative_predictive_value))\n",
    "print('F1 Score: {0:0.4f}'.format(f1_score))\n",
    "print('Balanced Accuracy: {0:0.4f}'.format(balanced_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd09de4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
